<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Background · LikelihoodBasedProfileWiseAnalysis.jl</title><meta name="title" content="Background · LikelihoodBasedProfileWiseAnalysis.jl"/><meta property="og:title" content="Background · LikelihoodBasedProfileWiseAnalysis.jl"/><meta property="twitter:title" content="Background · LikelihoodBasedProfileWiseAnalysis.jl"/><meta name="description" content="Documentation for LikelihoodBasedProfileWiseAnalysis.jl."/><meta property="og:description" content="Documentation for LikelihoodBasedProfileWiseAnalysis.jl."/><meta property="twitter:description" content="Documentation for LikelihoodBasedProfileWiseAnalysis.jl."/><meta property="og:url" content="https://JoelTrent.github.io/LikelihoodBasedProfileWiseAnalysis.jl/workflow_background/"/><meta property="twitter:url" content="https://JoelTrent.github.io/LikelihoodBasedProfileWiseAnalysis.jl/workflow_background/"/><link rel="canonical" href="https://JoelTrent.github.io/LikelihoodBasedProfileWiseAnalysis.jl/workflow_background/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">LikelihoodBasedProfileWiseAnalysis.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Background</a><ul class="internal"><li><a class="tocitem" href="#Observed-Data"><span>Observed Data</span></a></li><li><a class="tocitem" href="#Mechanistic-Mathematical-Model"><span>Mechanistic Mathematical Model</span></a></li><li><a class="tocitem" href="#Data-Distribution-Parameters"><span>Data Distribution Parameters</span></a></li><li><a class="tocitem" href="#Likelihood-Function"><span>Likelihood Function</span></a></li><li><a class="tocitem" href="#Profile-Likelihood-Function"><span>Profile Likelihood Function</span></a></li><li><a class="tocitem" href="#Confidence-Sets-For-Parameters"><span>Confidence Sets For Parameters</span></a></li><li><a class="tocitem" href="#Confidence-Sets-For-Data-Distribution-Parameters"><span>Confidence Sets For Data Distribution Parameters</span></a></li><li><a class="tocitem" href="#Reference-Tolerance-Sets-For-Observed-Data"><span>Reference Tolerance Sets For Observed Data</span></a></li></ul></li><li><span class="tocitem">User Interface</span><ul><li><a class="tocitem" href="../user_interface/initialisation/">Initialisation</a></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Parameter Profiles and Samples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../user_interface/profiles_and_samples/profile_structs/">Structs and Profile Types</a></li><li><a class="tocitem" href="../user_interface/profiles_and_samples/univariate/">Univariate Profiles</a></li><li><a class="tocitem" href="../user_interface/profiles_and_samples/bivariate/">Bivariate Profiles</a></li><li><a class="tocitem" href="../user_interface/profiles_and_samples/dimensional/">Dimensional Samples</a></li></ul></li><li><a class="tocitem" href="../user_interface/predictions/">Predictions</a></li><li><a class="tocitem" href="../user_interface/plots/">Plots</a></li><li><a class="tocitem" href="../user_interface/saving_and_loading/">Saving and Loading LikelihoodModels</a></li><li><a class="tocitem" href="../user_interface/timing_and_profiling/">Timing and Profiling</a></li><li><input class="collapse-toggle" id="menuitem-3-7" type="checkbox"/><label class="tocitem" for="menuitem-3-7"><span class="docs-label">Simulated Coverage Checks</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../user_interface/coverage/univariate_intervals/">Parameter Confidence Intervals</a></li><li><a class="tocitem" href="../user_interface/coverage/bivariate_boundaries/">Bivariate Parameter Confidence Boundaries</a></li><li><a class="tocitem" href="../user_interface/coverage/predictions_and_realisations/">Predictions and Realisations</a></li></ul></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/">Initial Setup</a></li><li><a class="tocitem" href="../examples/logistic/">Logistic Model</a></li><li><a class="tocitem" href="../examples/lotka-volterra/">Lotka-Volterra Model</a></li><li><a class="tocitem" href="../examples/two-species_logistic/">Two-Species Logistic Model</a></li><li><a class="tocitem" href="../examples/binomial_normal_approximation/">Gaussian Approximation of a Binomial Distribution</a></li><li><a class="tocitem" href="../examples/logistic_timing_estimates/">Function Evaluation Timing - Logistic Model</a></li></ul></li><li><span class="tocitem">Internal Library</span><ul><li><a class="tocitem" href="../internal_library/common/">Common Functions</a></li><li><a class="tocitem" href="../internal_library/initialisation/">Initialisation Internal</a></li><li><a class="tocitem" href="../internal_library/ellipse_likelihood/">Ellipse Functions</a></li><li><a class="tocitem" href="../internal_library/univariate/">Univariate Functions</a></li><li><a class="tocitem" href="../internal_library/bivariate/">Bivariate Functions</a></li><li><a class="tocitem" href="../internal_library/dimensional/">Dimensional Functions</a></li><li><a class="tocitem" href="../internal_library/predictions/">Prediction Functions</a></li><li><a class="tocitem" href="../internal_library/plots/">Plotting Functions</a></li><li><a class="tocitem" href="../internal_library/coverage/">Coverage Functions</a></li></ul></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Background</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Background</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JoelTrent/LikelihoodBasedProfileWiseAnalysis.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JoelTrent/LikelihoodBasedProfileWiseAnalysis.jl/blob/main/docs/src/workflow_background.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Background"><a class="docs-heading-anchor" href="#Background">Background</a><a id="Background-1"></a><a class="docs-heading-anchor-permalink" href="#Background" title="Permalink"></a></h1><p>Here we cover the background / general idea of the PWA workflow as seen in [<a href="../references/#simpsonprofilewise2023">1</a>]. We also introduce the idea of reference tolerance sets for predictions of realisations/observations within the workflow as formally introduced in my <a href="https://github.com/JoelTrent/UoA_MastersWorking">Masters thesis</a>.</p><p>This is a discussion of the workflow formulation from my <a href="https://github.com/JoelTrent/UoA_MastersWorking">Masters thesis</a>. Discussions which formed the basis of this section, minus reference tolerance intervals are in [<a href="../references/#simpsonprofilewise2023">1</a>] and [<a href="../references/#murphyimplementing2023">3</a>]. It is a little notation heavy, but hopefully it helps explain the sets and intervals available in the PWA workflow.</p><p>This summary uses models of the form &#39;deterministic mathematical model + error model&#39; as in [<a href="../references/#simpsonprofilewise2023">1</a>] and [<a href="../references/#murphyimplementing2023">3</a>], but it can also be used with stochastic models [<a href="../references/#simpsonreliable2022">4</a>].</p><h2 id="Observed-Data"><a class="docs-heading-anchor" href="#Observed-Data">Observed Data</a><a id="Observed-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Observed-Data" title="Permalink"></a></h2><p>Within the PWA workflow, observed data <span>$y_i^\textrm{o}$</span> is measured at discrete time points <span>$t_i$</span>. The &#39;o&#39; superscript distinguishes the observed data from the random variable <span>$y$</span> that generated the data. Given <span>$I$</span> observations, where <span>$i=1,2,3,..., I$</span>, observed data is collected into the vector, <span>$y_{1:I}^\textrm{o}$</span>, which corresponds to the time points <span>$t_{1:I}$</span>. For multiple observations from the same time point and model component distinct indices in <span>$1:I$</span> are used. For an observation of multiple model components at the same time point, we will use the same index in <span>$1:I$</span>, such that, e.g. <span>$y_{i}^\textrm{o} = (x_i^\textrm{o}, y_i^\textrm{o})$</span>.</p><h2 id="Mechanistic-Mathematical-Model"><a class="docs-heading-anchor" href="#Mechanistic-Mathematical-Model">Mechanistic Mathematical Model</a><a id="Mechanistic-Mathematical-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Mechanistic-Mathematical-Model" title="Permalink"></a></h2><p>Deterministic mechanistic models take the form:</p><p class="math-container">\[    z = f(\theta^M, t).\]</p><p>where <span>$\theta^M$</span> is a vector of mechanistic model parameters, and <span>$z$</span> is a scalar or vector of model solutions containing no error. Model solutions evaluated at discrete time points <span>$t_i$</span> are defined as <span>$z_i(\theta^M) = z(t_i; \theta^M)$</span>. This is also referred to as the model trajectory. In the same way as observations, <span>$z_{1:I}(\theta^M)$</span> is a vector of the model solution evaluated at <span>$t_{1:I}$</span>, while <span>$z(\theta^M)$</span> represents the continuous model solution. </p><h2 id="Data-Distribution-Parameters"><a class="docs-heading-anchor" href="#Data-Distribution-Parameters">Data Distribution Parameters</a><a id="Data-Distribution-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Distribution-Parameters" title="Permalink"></a></h2><p>The PWA workflow assumes that the observable data distribution can be characterised by a data/statistical model with parameters <span>$\phi(\theta)$</span>. The data distribution can be considered to come from an underlying mechanistic model with measurement error [<a href="../references/#simpsonprofilewise2023">1</a>], [<a href="../references/#murphyimplementing2023">3</a>].</p><p>If we assume that the observed data come from an underlying mechanistic model with measurement error, then we let: </p><p class="math-container">\[    \phi(\theta) = (z(\theta^M), \theta^\textrm{o}),\]</p><p>where typically (and here) the model solution is used as the mean or median parameter of the data distribution (error model) and <span>$\theta^\textrm{o}$</span> is any additional observation parameters like the observation error standard deviation. This gives us the full parameter vector, <span>$\theta = (\theta^M, \theta^\textrm{o})$</span>, for the mechanistic model and error model. For simplicity, the additional observation parameters, <span>$\theta^\textrm{o}$</span>, may be specified and regarded as known [<a href="../references/#simpsonprofilewise2023">1</a>]. However, unless they are truly known (as in, e.g. a synthetic coverage experiment), the likelihood function is known as an estimated likelihood function because it does not account for the uncertainty in <span>$\theta^\textrm{o}$</span> [<a href="../references/#pawitanall2001">2</a>].</p><p>At time points <span>$t_i$</span> we define:</p><p class="math-container">\[    \phi_i(\theta) = (z_i(\theta^M), \theta^\textrm{o}),\]</p><p>where <span>$z_i(\theta^M)$</span> is the mechanistic model solution at observation <span>$i$</span>.</p><p>In general, given data distribution parameters, we obtain a density function for the observed data <span>$y$</span> dependent on parameters, <span>$\theta$</span>, of the form:</p><p class="math-container">\[    y \sim p(y;\theta) = p(y;\phi(\theta)).\]</p><p>When measured at time point <span>$t_i$</span>, this becomes:</p><p class="math-container">\[    y_i \sim p(y_i;\theta) = p(y_i;\phi_i(\theta)).\]</p><p>When the data distribution parameters are for an error model such as the additive Gaussian, log-normal and logit-normal models, the density function for <span>$y$</span> can be represented in the following ways.</p><p>For the additive Gaussian model, this is represented as [<a href="../references/#murphyimplementing2023">3</a>]:</p><p class="math-container">\[    y_i \sim p(y_i ; \theta) \sim \mathcal{N}(\phi_i(\theta)) \sim \mathcal{N}(z_i(\theta^M), \theta^\textrm{o}) \sim \mathcal{N}(z_i(\theta^M), \sigma^2_N),\]</p><p>where <span>$\theta^\textrm{o} = \sigma_N$</span>. This is equivalent to representing the observed data as the model trajectory plus error from a normal distribution with zero mean and variance, <span>$\sigma^2_N$</span>.</p><p>For the log-normal model, this is represented as [<a href="../references/#murphyimplementing2023">3</a>]:</p><p class="math-container">\[    y_i \sim \text{LogNormal}(\log(z_i(\theta^M)), \sigma^2_L),\]</p><p>where <span>$\theta^\textrm{o} = \sigma_L$</span>.</p><p>The logit-normal model is represented similarly to the log-normal model, noting that the mechanistic model solution is a proportion defined <span>$\in (0,1)$</span>:</p><p class="math-container">\[    y_i \sim \text{LogitNormal}(\text{logit}(z_i(\theta^M)), \sigma^2_{L}),\]</p><p>where <span>$\theta^\textrm{o} = \sigma_L$</span> and <span>$\text{logit}(p)=\log(p\div (1-p))$</span>.</p><h2 id="Likelihood-Function"><a class="docs-heading-anchor" href="#Likelihood-Function">Likelihood Function</a><a id="Likelihood-Function-1"></a><a class="docs-heading-anchor-permalink" href="#Likelihood-Function" title="Permalink"></a></h2><p>If we have a vector of independent observations <span>$y_{1:I}^\textrm{o}$</span> from our density function, <span>$y$</span>, which is a function of parameter <span>$\theta$</span>, we can define the normalised likelihood function, <span>$\hat{\mathcal{L}}(\theta ; y_{1:I}^{\textrm{o}})$</span>, and in particular the normalised log-likelihood function, <span>$\hat{\ell} \left(\theta \, ; \, y_{1:I}^{\textrm{o}}\right)$</span>. The &#39;hat&#39;, <span>$\hat{}$</span>, on <span>$\mathcal{L}$</span> and <span>$\ell$</span> is used to represent that the functions are normalised.</p><p>The normalised likelihood function is [<a href="../references/#sprottstatistical2008">5</a>]:</p><p class="math-container">\[    \hat{\mathcal{L}}(\theta ; y_{1:I}^{\textrm{o}}) =
    \frac{p(y_{1:I}^{\textrm{o}} ; \phi(\theta) )}{\sup\limits_{\theta} \hspace{0.1cm} p(y_{1:I}^{\textrm{o}};\phi(\theta))}.\]</p><p>where the numerator is the likelihood function evaluated for data distribution parameters <span>$\phi(\theta)$</span> at observations <span>$y_{1:I}^{\textrm{o}}$</span> and the denominator is the maximum likelihood estimate (MLE) of the likelihood function as <span>$\theta$</span> varies. The MLE will be estimated using numerical optimisation, with bounds on parameters, which have value <span>$\hat{\theta}$</span> at the MLE.</p><p>Here, we will work with the normalised log-likelihood function of the form:</p><p class="math-container">\[\begin{equation}
\begin{split}
    \hat{\ell} \left(\theta \, ; \, y_{1:I}^{\textrm{o}}\right) &amp;= \log \hat{\mathcal{L}}(\theta ; y_{1:I}^{\textrm{o}})\\
    &amp;= \log p(y_{1:I}^{\textrm{o}} ; \phi(\theta) ) - \sup_{\theta} \log p(y_{1:I}^{\textrm{o}} ; \phi(\theta) )\\
    &amp;= \sum_{i=1}^{I} \log p(y_i^{\textrm{o}} ; \phi(\theta) )- \sup_{\theta}\sum_{i=1}^{I} \log p(y_i^{\textrm{o}} ; \phi(\theta)).
\end{split}
\end{equation}\]</p><p>Normalisation of the log-likelihood function means that <span>$\hat{\ell} \left(\theta \, ; \, y_{1:I}^{\textrm{o}}\right) \leq 0$</span> and <span>$\hat{\ell} (\hat{\theta} \, ; \, y_{1:I}^{\textrm{o}}) = 0$</span>.</p><p>We generally recommend using the <code>loglikelihood</code> function implemented in <a href="https://juliastats.org/Distributions.jl/stable/">Distributions.jl</a> to determine the value of the log-likelihood function, as in our examples. This is straightforward to compute for the error models described in <a href="#Data-Distribution-Parameters">Data Distribution Parameters</a> given observed data <span>$y_{1:I}^\textrm{o}$</span>.</p><h2 id="Profile-Likelihood-Function"><a class="docs-heading-anchor" href="#Profile-Likelihood-Function">Profile Likelihood Function</a><a id="Profile-Likelihood-Function-1"></a><a class="docs-heading-anchor-permalink" href="#Profile-Likelihood-Function" title="Permalink"></a></h2><p>Given a likelihood function, we can define a profile log-likelihood function as a function of interest parameters, <span>$\psi$</span>, and nuisance parameters, <span>$\omega$</span>. These parameters represent a partitioning of the parameter vector <span>$\theta = (\psi, \omega)$</span>. The normalised profile log-likelihood function is then:</p><p class="math-container">\[    \hat{\ell}_p \left(\psi \, ; \, y_{1:I}^{\textrm{o}}\right) = \sup_{\omega \, | \, \psi} \hat{\ell}_p \left(\psi, \, \omega \, ; \, y_{1:I}^{\textrm{o}}\right),\]</p><p>where for given values of the interest parameter <span>$\psi$</span>, the values of <span>$\omega$</span> are optimised out, meaning they are set to the values that maximise the function. We expect that this function will be continuous for the models considered.</p><h2 id="Confidence-Sets-For-Parameters"><a class="docs-heading-anchor" href="#Confidence-Sets-For-Parameters">Confidence Sets For Parameters</a><a id="Confidence-Sets-For-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Confidence-Sets-For-Parameters" title="Permalink"></a></h2><p>Using the log-likelihood function, we define approximate likelihood-based confidence sets for the full parameter vector <span>$\theta$</span> [<a href="../references/#pawitanall2001">2</a>], [<a href="../references/#sprottstatistical2008">5</a>]:</p><p class="math-container">\[    \mathcal{C}_{\theta, 1-\alpha}(y_{1:I}^{\textrm{o}}) = \{ \theta \, | \, \hat{\ell} \left(\theta \, ; \, y_{1:I}^{\textrm{o}}\right) \geq \ell_c \},\]</p><p>where <span>$\ell_c$</span> is a threshold chosen so that the approximate coverage of the confidence interval is <span>$1-\alpha$</span>. For sufficiently regular problems (see Section \ref{sssec:loglikelihood_approx}) the threshold is calibrated using the chi-square distribution. Regular means that the likelihood function is well approximated by a quadratic function around the MLE [<a href="../references/#pawitanall2001">2</a>]:</p><p class="math-container">\[\ell_c = - \frac{\Delta_{\nu, 1-\alpha}}{2},\]</p><p>where <span>$\Delta_{\nu, 1-\alpha}$</span> is the <span>$1-\alpha$</span> quantile of the <span>$\chi^2$</span> distribution with <span>$\nu$</span> degrees of freedom. We will refer to these as full parameter confidence sets. For full parameter confidence sets, we set <span>$\nu$</span> equal to the number of parameters, <span>$|\theta|$</span>. </p><p>Profile likelihood-based confidence sets for the interest parameter(s) <span>$\psi$</span> take the form:</p><p class="math-container">\[    \mathcal{C}^\psi_{\theta, 1-\alpha}(y_{1:I}^{\textrm{o}}) = \{ \theta=(\psi, \omega) \,| \, \hat{\ell}_p \left(\psi \, ; \, y_{1:I}^{\textrm{o}}\right) \geq \ell_c \},\]</p><p>where we instead set <span>$\nu$</span> equal to the dimensionality of the interest parameters (e.g. for confidence sets with a single interest parameter <span>$\nu=1$</span> and with two interest parameters <span>$\nu=2$</span>). We also record the optimised out values of nuisance parameters, <span>$\omega$</span>, in the confidence set for the interest parameter. Recording these nuisance parameters allows this set to be propagated forward into predictive quantities; they do not have to be recorded otherwise. Simultaneous profile likelihood-based confidence sets for interest parameters can be obtained by setting <span>$\nu=|\theta|$</span> [<a href="../references/#rauestructural2009">6</a>]. </p><p>We refer to profile likelihood-based confidence sets for one and two interest parameters as univariate profiles and bivariate profiles, respectively. We let the labels &#39;univariate&#39; or &#39;bivariate&#39; relate to profiles formed using <span>$\nu$</span> equal to the dimensionality of the interest parameter, <span>$|\psi|$</span>. If the profiles are instead created using the simultaneous asymptotic threshold with <span>$\nu=|\theta|$</span>, they will be referred to as &#39;simultaneous univariate&#39; or &#39;simultaneous bivariate&#39; profiles. Setting <span>$\nu$</span> to any other value may not have a clear statistical interpretation.</p><h2 id="Confidence-Sets-For-Data-Distribution-Parameters"><a class="docs-heading-anchor" href="#Confidence-Sets-For-Data-Distribution-Parameters">Confidence Sets For Data Distribution Parameters</a><a id="Confidence-Sets-For-Data-Distribution-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Confidence-Sets-For-Data-Distribution-Parameters" title="Permalink"></a></h2><p>By propagating forward full parameter confidence sets and profile likelihood-based confidence sets using the mapping <span>$\phi(\theta)$</span>, we define approximate likelihood-based confidence sets for the data distribution parameters <span>$\phi$</span>. We refer to the data distribution parameters, <span>$\phi$</span>, as &#39;predictive&#39; quantities [<a href="../references/#simpsonprofilewise2023">1</a>]. We use square brackets in the following equations to show that the confidence set for data distribution parameters is the set image of the parameter confidence set under the mapping <span>$\phi(\theta)$</span>. </p><p>For the likelihood-based confidence set for data distribution parameters from full parameter confidence sets, this is defined as:</p><p class="math-container">\[    \mathcal{C}_{\phi,1-\alpha}(y_{1:I}^\textrm{o}) = \{\phi[\mathcal{C}_{\theta,1-\alpha}(y_{1:I}^\textrm{o})]\} = \{\phi(\theta) \ \vert\ \ \theta \in \mathcal{C}_{\theta,1-\alpha}(y_{1:I}^\textrm{o})\}.\]</p><p>This set definition implies that the confidence set <span>$\mathcal{C}_{\phi,1-\alpha}(y_{1:I}^\textrm{o})$</span> has at least a coverage of <span>$1-\alpha$</span> (is conservative) given the following relationship [<a href="../references/#simpsonprofilewise2023">1</a>]:</p><p class="math-container">\[    \theta \in \mathcal{C}_{\theta,1-\alpha} \implies \phi(\theta) \in \mathcal{C}_{\phi,1-\alpha}.\]</p><p>For a profile likelihood-based confidence set, a profile-wise confidence set, this is defined as:</p><p class="math-container">\[    \mathcal{C}_{\phi,1-\alpha}^\psi(y_{1:I}^\textrm{o}) = \{\phi[\mathcal{C}^\psi_{\theta,1-\alpha}(y_{1:I}^\textrm{o})]\} = \{\phi(\theta) \ \vert\ \theta \in \mathcal{C}^\psi_{\theta,1-\alpha}(y_{1:I}^\textrm{o})\}.\]</p><p>More conservative profile-wise confidence sets for data distribution parameters can be formed by taking the union of individual profile confidence sets:</p><p class="math-container">\[    \mathcal{C}_{\phi,1-\alpha} \approx \bigcup_\psi \mathcal{C}^\psi_{\phi,1-\alpha}.\]</p><p>Additionally, we can obtain more conservative profile-wise confidence sets for data distribution parameters by forming simultaneous profile confidence sets with <span>$\nu=|\theta|$</span> rather than <span>$\nu=|\psi|$</span>.</p><p>When considered in a mechanistic model context, this allows us to form a trajectory confidence set for the mechanistic model solution, which is typically treated as the mean or median data distribution parameter [<a href="../references/#simpsonprofilewise2023">1</a>], [<a href="../references/#murphyimplementing2023">3</a>]. If we wish to form a trajectory confidence set for the mechanistic model solution, we consider just that component of the data distribution confidence set. In this case, if the parameter confidence set has the correct coverage properties over all parameters simultaneously, we expect the trajectory confidence set, <span>$\mathcal{C}_{\phi,1-\alpha}$</span>, to display <em>curvewise</em> (simultaneous) coverage properties, where the true model solution is fully contained within the confidence set [<a href="../references/#murphyimplementing2023">3</a>].  </p><p>We refer to likelihood-based confidence sets for the model trajectory from full parameter confidence sets as full trajectory confidence sets. Similarly, we refer to the sets for the data distribution parameters as full data distribution confidence sets. Additionally, we refer to profile-wise confidence sets for the model trajectory from univariate and bivariate profiles as profile-wise trajectory confidence sets. </p><h2 id="Reference-Tolerance-Sets-For-Observed-Data"><a class="docs-heading-anchor" href="#Reference-Tolerance-Sets-For-Observed-Data">Reference Tolerance Sets For Observed Data</a><a id="Reference-Tolerance-Sets-For-Observed-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Reference-Tolerance-Sets-For-Observed-Data" title="Permalink"></a></h2><p>W define <span>$(1-\delta, 1-\alpha)$</span> reference tolerance sets for observed data given <span>$1-\delta$</span> population reference sets [<a href="../references/#wrightcalculating1999">7</a>], [<a href="../references/#katkiassessing2005">8</a>]. For more background, please see my <a href="https://github.com/JoelTrent/UoA_MastersWorking">Masters thesis</a>. This is in contrast to more traditional prediction sets for observed data.</p><p>The <span>$1-\delta$</span> population reference interval refers to an interval that contains <span>$1-\delta$</span> of the population (i.e. of observations) [<a href="../references/#wrightcalculating1999">7</a>], [<a href="../references/#katkiassessing2005">8</a>]. These population reference intervals are also &#39;predictive&#39; quantities. Here, a <span>$1-\delta$</span> population reference set refers to the set of <span>$1-\delta$</span> population reference intervals across time points, <span>$t_j$</span> (and similarly for reference tolerance sets and reference tolerance intervals). In general, we will take a <span>$1-\delta$</span> population reference interval to be given by the <span>$1-\delta$</span> highest density region [<a href="../references/#hyndmancomputing1996">9</a>] of population observations at <span>$t_j$</span>, as this allows the interval to represent a &#39;typical&#39; observation best. For the error models discussed in <a href="#Data-Distribution-Parameters">Data Distribution Parameters</a> we use <a href="https://joeltrent.github.io/UnivariateUnimodalHighestDensityRegion.jl/stable/">UnivariateUnimodalHighestDensityRegion.jl</a> as seen in <a href="../user_interface/predictions/#Predefined-Error-models">Predefined Error models</a>.</p><p>Similarly, a <span>$(1-\delta, 1-\alpha)$</span> reference tolerance interval is a tolerance interval that contains the <span>$1-\delta$</span> reference interval with probability <span>$1-\alpha$</span>. We refer to these as reference tolerance intervals unless the <span>$(1-\delta, 1-\alpha)$</span> designation is important for clarity. These intervals can be used as approximate prediction intervals; they appear to be appropriate for trapping at least <span>$1-\delta$</span> of observations with confidence <span>$1-\alpha$</span>, which is a weaker condition than trapping the <span>$1-\delta$</span> population reference interval. As our notation suggests, a reference tolerance interval can be formed that has a coverage property at a different confidence level to the size of the reference interval (i.e. <span>$\delta \neq \alpha$</span>).</p><p>Therefore, given a desired confidence level <span>$1-\alpha$</span>, we form a <span>$1-\alpha$</span> likelihood-based confidence set for data distribution parameters, <span>$\mathcal{C}_{\phi,1-\alpha}$</span>, from the full parameter confidence set. Then, for each <span>$\phi$</span> in the data distribution parameter set we construct a <span>$1-\delta$</span> reference set, <span>$\mathcal{A}_{y,1-\delta}(y^\textrm{o}_{1:I})$</span>, where <span>$\phi$</span> is related to <span>$y$</span> as in the density function equation in <a href="#Data-Distribution-Parameters">Data Distribution Parameters</a>. This reference set is constructed by taking a <span>$1-\delta$</span> region of the data distribution. For symmetric data distributions, we take the <span>$\delta/2$</span> and <span>$1-\delta/2$</span> quantiles of the probability distribution. For asymmetric distributions, we take the <span>$1-\delta$</span> highest density region [<a href="../references/#hyndmancomputing1996">9</a>]. If the asymmetric distribution is unimodal we can use <a href="https://joeltrent.github.io/UnivariateUnimodalHighestDensityRegion.jl/stable/">UnivariateUnimodalHighestDensityRegion.jl</a> to evaluate the highest density region. We then take the union across the reference sets formed from each <span>$\phi$</span> to obtain <span>$(1-\delta, 1-\alpha)$</span> reference tolerance sets for observed data, <span>$y^\textrm{o}$</span>, from full parameter confidence sets:</p><p class="math-container">\[    \mathcal{C}_{y, (1-\delta, 1-\alpha)}(y^\textrm{o}_{1:I}) \approx \bigcup_{\phi \ \in \ \mathcal{C}_{\phi,1-\alpha}(y^\textrm{o}_{1:I})} \mathcal{A}_{y,1-\delta}(y^\textrm{o}_{1:I}).\]</p><p>Because each <span>$\mathcal{A}_{y,1-\delta}(y^\textrm{o}_{1:I})$</span> can only be guaranteed to contain the population reference set if it was derived using the true parameter values, we refer to these only as <em>reference sets</em>. Similarly, because <span>$\mathcal{C}_{y,(1-\delta, 1-\alpha)}(y^\textrm{o}_{1:I})$</span> is obtained by taking the union over each reference set, it is much more likely that one of these was obtained from the true parameter values. Hence, we refer to these as <em>reference tolerance sets</em>. Usefully, if the data distribution parameter confidence set, <span>$\mathcal{C}_{\phi,1-\alpha}$</span>, has curvewise coverage properties then we also expect the reference tolerance set, <span>$\mathcal{C}_{y,(1-\delta, 1-\alpha)}(y^\textrm{o}_{1:I})$</span>, to have curvewise coverage properties. We refer to these as full reference tolerance sets.</p><p>We do the same thing for profile-wise reference tolerance sets, beginning from profile-wise data distribution confidence sets:</p><p class="math-container">\[    \mathcal{C}^\psi_{y,(1-\delta, 1-\alpha)}(y^\textrm{o}_{1:I}) \approx \bigcup_{\phi \ \in \ \mathcal{C}^\psi_{\phi,1-\alpha}(y^\textrm{o}_{1:I})} \mathcal{A}^\psi_{1-\delta}(y^\textrm{o}_{1:I}).\]</p><p>More conservative profile-wise reference tolerance sets can again be formed by taking the union of reference tolerance sets from individual profiles:</p><p class="math-container">\[    \mathcal{C}_{y,(1-\delta, 1-\alpha)} \approx \bigcup_\psi \mathcal{C}^\psi_{y,(1-\delta, 1-\alpha)}.\]</p><p>We refer to these as profile-wise reference tolerance sets.</p><h3 id="Full-Reference-Tolerance-Set-Coverage"><a class="docs-heading-anchor" href="#Full-Reference-Tolerance-Set-Coverage">Full Reference Tolerance Set Coverage</a><a id="Full-Reference-Tolerance-Set-Coverage-1"></a><a class="docs-heading-anchor-permalink" href="#Full-Reference-Tolerance-Set-Coverage" title="Permalink"></a></h3><p>The coverage of the full reference tolerance set in the PWA workflow is straightforward to prove. The <span>$(1-\delta, 1-\alpha)$</span> reference tolerance set is constructed from the <span>$1-\alpha$</span> confidence set for data distribution parameters, which is constructed from the <span>$1-\alpha$</span> confidence set for parameters. Here let <span>$1-\delta = 1-\alpha = 0.95 = 95\%$</span>. If a full parameter confidence set has 95% coverage and the model is well-specified, then 95% of the time it will trap the true parameters. Therefore, the full data distribution confidence set will also have 95% coverage. Additionally, the true data distribution parameters give the true <span>$1-\delta$</span> reference interval for the population at each time point. Hence, if the full data distribution confidence set has 95% coverage, then our full reference tolerance set will contain the 95% reference set <em>at least</em> 95% of the time. </p><p>In the mechanistic model case, if the full data distribution confidence set has curvewise coverage of the model solution, then our full reference tolerance set will also have curvewise coverage of the population reference set. That is, 95% of the full reference tolerance sets constructed in this fashion under repeated sampling of new data will contain the 95% population reference set (all 95% population reference intervals). A similar idea to what we demonstrate here, but in a different context, is found in [<a href="../references/#sattenupper1995">10</a>]. </p><p>For example, consider a single parameter scalar model, <span>$z(\theta^M) = \theta^M$</span>, from which we have obtained <span>$I=100$</span> observations corrupted by i.i.d. Gaussian noise <span>$\sim \mathcal{N}(0,\theta^\textrm{o})$</span>. Let <span>$\theta^M=2$</span> and <span>$\theta^\textrm{o}=1$</span>. The density function for observations is represented as:</p><p class="math-container">\[    y \sim p(y ; \theta)  \sim \mathcal{N}(\phi(\theta)) \sim \mathcal{N}(z(\theta^M), \theta^\textrm{o}) \sim \mathcal{N}(z(\theta^M), \sigma),\]</p><p>where <span>$\theta^\textrm{o}=\sigma$</span> and <span>$\theta = (\theta^M, \theta^\textrm{o})$</span>. Resultantly, our parameter vector, <span>$\theta$</span>, has two parameters. </p><p>The 95% population reference interval can be formed by considering the 2.5% and 97.5% quantiles of this density function under the true parameterisation, <span>$\theta =[0.040, 3.960]$</span>. Then, given the <span>$I$</span> observations we form a 95% confidence set for <span>$\theta$</span>, <span>$\mathcal{C}_{\theta, 0.95}$</span>. The mapping of <span>$\theta$</span> onto the data distribution parameters <span>$\phi$</span> is 1:1, hence we also have a 95% confidence set for <span>$\phi$</span>, <span>$\mathcal{C}_{\phi, 0.95}$</span>. We then use each <span>$\phi \in \mathcal{C}_{\phi, 0.95}$</span> to form 95\% reference intervals, <span>$\mathcal{A}_{y, 0.95}$</span>. We then take the union across each of these reference intervals to form (95%, 95%) reference tolerance intervals, <span>$\mathcal{C}_{y, (0.95,0.95)}$</span>. If the true parameterisation is in <span>$\mathcal{C}_{\theta, 0.95}$</span> with 95% coverage, then it is also in <span>$\mathcal{C}_{\phi, 0.95}$</span> with 95% coverage and our full reference tolerance interval, <span>$\mathcal{C}_{y, (0.95, 0.95)}$</span>, will also contain the <em>at least</em> 95% reference interval with <em>at least</em> 95% coverage. </p><p>The &#39;at least&#39; statement for both the reference interval and the coverage of this interval occurs for the following reasons. For the coverage statement, if <span>$\theta \notin \mathcal{C}_{\theta, 0.95}$</span>, then it is possible that we predict the population reference interval using the incorrect parameter or similarly from the union of reference intervals from many incorrect parameters. Similarly, for the reference interval statement, if <span>$\theta \in \mathcal{C}_{\theta, 0.95}$</span>, then our 95% reference interval from that <span>$\theta$</span> is the 95% population reference interval. Other parameter values in the parameter confidence set may predict reference intervals outside of this range. Hence, the union of these intervals will contain at least the 95% population reference interval.</p><p>Code to visualise and test this example is seen below:</p><h4 id="Setup"><a class="docs-heading-anchor" href="#Setup">Setup</a><a id="Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Setup" title="Permalink"></a></h4><pre><code class="language-julia hljs">using Random, Distributions
using LaTeXStrings
using LikelihoodBasedProfileWiseAnalysis

θ_true = [2,1]
true_dist = Normal(θ_true[1], θ_true[2])
n = 100
Random.seed!(3)
y_obs = rand(true_dist, n) 

ref_interval = quantile(true_dist, [0.025, 0.975])

data = (y_obs=y_obs, dist=Normal(0, θ_true[2]), t=[&quot;z&quot;])

function lnlike(θ, data)
    return sum(loglikelihood(Normal(0, θ[2]), data.y_obs .- θ[1]))
end

function predictfunction(θ, data, t=[&quot;z&quot;])
    return [θ[1]*1.0]
end

errorfunction(a,b,c) = normal_error_σ_estimated(a,b,c, 2)</code></pre><h4 id="Parameter-Confidence-Set-Evaluation"><a class="docs-heading-anchor" href="#Parameter-Confidence-Set-Evaluation">Parameter Confidence Set Evaluation</a><a id="Parameter-Confidence-Set-Evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Parameter-Confidence-Set-Evaluation" title="Permalink"></a></h4><pre><code class="language-julia hljs">model = initialise_LikelihoodModel(lnlike, predictfunction, errorfunction, data, [:μ, :σ], [2.,1.], [-1., 0.01], [5., 5.], [1.,1.]);

univariate_confidenceintervals!(model, num_points_in_interval=300)
dimensional_likelihood_samples!(model, 2, 1000000)</code></pre><h4 id="Confidence-Set-Plots"><a class="docs-heading-anchor" href="#Confidence-Set-Plots">Confidence Set Plots</a><a id="Confidence-Set-Plots-1"></a><a class="docs-heading-anchor-permalink" href="#Confidence-Set-Plots" title="Permalink"></a></h4><pre><code class="language-julia hljs">using Plots; gr()
format=(size=(400,400), dpi=300, title=&quot;&quot;, legend_position=:topright)

plt = plot_univariate_profiles(model; format...)
vline!(plt[1], [θ_true[1]], label=L&quot;\theta^M&quot;, xlabel=L&quot;\theta^M&quot;, lw=2, linestyle=:dash)
vline!(plt[2], [θ_true[2]], label=L&quot;\theta^\textrm{o}&quot;, xlabel=L&quot;\theta^M&quot;, lw=2, linestyle=:dash)
display(plt[1])
display(plt[2])

plt = plot_bivariate_profiles(model; for_dim_samples=true, markeralpha=0.4, max_internal_points=10000, ylabel=latexstring(&quot;\\theta^\\textrm{o}&quot;), xlabel=latexstring(&quot;\\theta^M&quot;), format...)
scatter!(plt[1], [θ_true[1]], [θ_true[2]], label=&quot;θtrue&quot;, color=&quot;black&quot;, ms=5, msw=0)
display(plt[1])</code></pre><h4 id="Profile-Wise-Reference-Intervals-and-Reference-Tolerance-Intervals-From-Univariate-Profiles"><a class="docs-heading-anchor" href="#Profile-Wise-Reference-Intervals-and-Reference-Tolerance-Intervals-From-Univariate-Profiles">Profile-Wise Reference Intervals and Reference Tolerance Intervals From Univariate Profiles</a><a id="Profile-Wise-Reference-Intervals-and-Reference-Tolerance-Intervals-From-Univariate-Profiles-1"></a><a class="docs-heading-anchor-permalink" href="#Profile-Wise-Reference-Intervals-and-Reference-Tolerance-Intervals-From-Univariate-Profiles" title="Permalink"></a></h4><pre><code class="language-julia hljs">generate_predictions_univariate!(model, [&quot;z&quot;], 1.0)
lq = model.uni_predictions_dict[1].realisations.lq
uq = model.uni_predictions_dict[1].realisations.uq

plt = plot(1:length(lq), transpose(uq); xlabel=&quot;Confidence Set Sample&quot;, ylabel=&quot;Interval&quot;, label=&quot;Upper&quot;, palette=:Paired_6, format...)
plot!(1:length(lq), transpose(lq), label=&quot;Lower&quot;)

lq = model.uni_predictions_dict[2].realisations.lq
uq = model.uni_predictions_dict[2].realisations.uq

plt = plot(1:length(lq), transpose(uq); xlabel=&quot;Confidence Set Sample&quot;, ylabel=&quot;Interval&quot;, label=&quot;Upper&quot;, palette=:Paired_6, format...)
plot!(1:length(lq), transpose(lq), label=&quot;Lower&quot;)

extrema1 = model.uni_predictions_dict[1].realisations.extrema
extrema2 = model.uni_predictions_dict[2].realisations.extrema
extrema = [min(extrema1[1],extrema2[1]) max(extrema1[2], extrema2[2])]

using StatsPlots
plt = plot(true_dist; xlabel=latexstring(&quot;y&quot;), label=&quot;Density&quot;, fill=(0, 0.3), palette=:Paired_6, format...)
vline!(ref_interval, label=&quot;Reference&quot;, lw=2)
vline!(transpose(extrema1), label=&quot;Tolerance, &quot;*L&quot;\psi=\theta^M&quot;, linestyle=:dash, lw=2)
vline!(transpose(extrema2), label=&quot;Tolerance, &quot;*L&quot;\psi=\theta^\textrm{o}&quot;, linestyle=:dash, lw=3)
vline!(transpose(extrema), label=&quot;Tolerance, union&quot;, linestyle=:dashdot, lw=2, alpha=0.7)</code></pre><h4 id="Full-Reference-Tolerance-Interval"><a class="docs-heading-anchor" href="#Full-Reference-Tolerance-Interval">Full Reference Tolerance Interval</a><a id="Full-Reference-Tolerance-Interval-1"></a><a class="docs-heading-anchor-permalink" href="#Full-Reference-Tolerance-Interval" title="Permalink"></a></h4><pre><code class="language-julia hljs">generate_predictions_dim_samples!(model, [&quot;z&quot;], 1.0)
lq = model.dim_predictions_dict[1].realisations.lq
uq = model.dim_predictions_dict[1].realisations.uq
extrema=model.dim_predictions_dict[1].realisations.extrema

plt = plot(1:length(lq), transpose(uq); xlabel=&quot;Confidence Set Sample&quot;, ylabel=&quot;Interval&quot;, label=&quot;Upper&quot;, palette=:Paired_6, format...)
plot!(1:length(lq), transpose(lq), label=&quot;Lower&quot;)

plt = plot(true_dist; xlabel=latexstring(&quot;y&quot;),label=&quot;Density&quot;, fill=(0, 0.3), palette=:Paired_6, format...)
vline!(ref_interval, label=&quot;Reference&quot;, lw=2)
vline!(transpose(extrema), label=&quot;Tolerance&quot;, linestyle=:dash, lw=2)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../user_interface/initialisation/">Initialisation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Tuesday 13 February 2024 01:21">Tuesday 13 February 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
